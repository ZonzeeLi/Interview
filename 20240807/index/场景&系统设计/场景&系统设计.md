# 场景&系统设计

## 场景

### 数据处理（分治）

#### 1. 海量日志数据，提取出某日访问百度次数最多的 IP

如果想一次性把所有 IP 装进内存中，容量显然不够，针对大数据问题，可以把大文件转换成小文件（取模映射）。

1. 分治 / hash 映射

首先把这一天访问百度日志的所有 IP 提取出来，然后逐个写入到一个大文件中，接着采用映射的方法，比如 %1000，把整个大文件映射为 1000 个小文件。

2. hash_map 统计

当大文件转换成小文件，便可以采用 hash_map 分别对 1000个小文件中的 IP 进行频率统计，再找出每个小文件中出现频率最大的那个 IP。

3. 堆 / 快速排序

统计处 1000 个频率最大的 IP 后，依据各自频率的大小进行排序，按时间复杂度或者空间复杂度考虑排序算法。

### 业务—订单场景

#### 1. 一笔订单，在取消的那一刻，用户刚好付款了，怎么办？

订单会有定时取消的逻辑，所以会出现用户卡点付款的场景，所以会出现两种情况：

1. 用户支付成功，支付回调的那一刻支付单刚好还没取消，而等回调结束，取消支付单的事务提交，支付单取消。此时用户扣款了，但是对应的资产没了。
2. 用户支付成功，支付回调的那一刻支付单已经被取消。但此时用户已经扣款，东西没了。

这种场景是支付单支付成功和取消的两种状态竞争，正常情况下，订单或者支付单都会有状态机的存在，在当前场景简单来说有以下两条路径：

1. 待支付->支付中->支付成功
2. 待支付->支付中->已取消

针对上述的情况 1 就是路径 1，针对情况 2 就是路径 2

所以在修改支付单状态的时候，基于原始状态的判断，就可以正常的处理

```sql
# 支付成功
update pay_info set status = 'paySuccess' where orderNo = '1' and status = 'paying';

# 取消
update pay_info set status = 'cancel' where orderNo = '1' and status = 'paying';
```

当加了`status = 'paying'`就可以保证一个成功一个失败。当情况 1 执行成功，那么取消的 sql 必定执行失败，不需要做额外的处理。当情况 2 执行成功，订单被取消，支付成功的 sql 必然失败，这时候就要逆向处理，给用户退款。

这里在业务上有一个优化，用户可能会纠结在最后一刻决定付款，如果这时候被告知退款，可能不会再下单了，因此可以在页面上限时订单倒计时为 10 分钟，实际的后端是延迟 11 分钟取消。

除了利用数据库的处理，还可以使用分布式锁，对一笔订单加锁也能保证这笔订单正常的业务流转。

#### 2. 项目上发现出现很多重复订单，怎么预防处理？

出现重复订单的情况是因为系统针对下单的方法没有做幂等的设计。

大致可以通过两种方式来实现下单的幂等：

1. 数据库唯一约束

可以将订单号作为数据库的主键或者唯一索引，这样一来，数据库就会拒绝重复插入的情况，避免重复订单。

2. 分布式锁

可以用分布式锁来避免多个请求同时处理同一笔订单的情况，这里需要注意的是，lock 的 key 要以`order_lock_{orderID}`这种订单号的维度加锁，避免同笔订单多次插入的同时锁的粒度也足够细。

如果只以`order_lock`作为 key，那么下单的方法并发度就是 1，性能会下降。

## 系统设计

### 下游存储（Redis、DB）

#### 1. 线上发现 Redis 机器爆了，如何优化？

首先要观察是 Redis 的哪方面出问题，比如内存、CPU、带宽等等。

如果是内存耗尽，可能需要增加机器的内存，或者利用 Redis 集群分片，将数据分散到多个实例，即水平扩展。

如果是 CPU 使用率飙升，首先看是否有大量的读写请求，且涉及到复杂度较高的命令，比如聚合、排序等等，需要针对业务评估优化，是否将一些操作放到后端服务自己处理，也可以使用 Redis 集群分片，分散计算压力。也可能是有大量的 key 突然过期，这也同样需要评估业务场景。

如果是带宽方面，则需要增加带宽配置，加大带宽。

上面三种情况还可以利用存储结构的改进来进一步优化，比如利用 hash 来替换多个 string 键来存储相似的数据。将一些包含大量数据的大 key 拆分成多个小 key。

除了集群分片手段，还可以利用本地缓存来降低 Redis 的负载。

一些热点数据可以存储在后端服务本地，请求先打到后端服务，如果命中本地缓存，则不需要请求 Redis 直接返回，这种情况就减轻了 Redis 的压力，解决集群内单机负载高的情况。

#### 2. 项目上有个导出 excel 发现很慢，怎么优化？

这种导出 excel 慢大概率就是两种情况，获取数据慢和写入数据慢。

针对于获取数据，可以在业务逻辑的处理上，从单次 rpc 调用改成批量 rpc 调用，如果是查询 db 慢，看是否使用了索引或者有什么排序逻辑等，一般这种查询都是分页查询，可以将普通分页使用的`limit offset, size`变成记录上一次查询的`id`为`lastID`，下一次查询带上`lastID`作为查询条件。比如：

```sql
select * from table where id > lastID + (其他条件) order by id asc limit size;
```

因为`limit offset, size`的效率比较低，例如`limit 10000000, 10`，则是一直扫描到 10000000 后，跳过它们，再取接下来的 10 条数据，对数据库来说需要大量的 I/O操作。

而写入 excel 慢的场景，就避免一行一行的写入，改成批量写入数据。

### 系统指标

#### 1. CPU 飙高异常，可能出现的场景和排查解决思路