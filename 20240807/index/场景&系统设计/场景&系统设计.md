# 场景&系统设计

## 场景

### 数据处理（分治）

#### 1. 海量日志数据，提取出某日访问百度次数最多的 IP

如果想一次性把所有 IP 装进内存中，容量显然不够，针对大数据问题，可以把大文件转换成小文件（取模映射）。

1. 分治 / hash 映射

首先把这一天访问百度日志的所有 IP 提取出来，然后逐个写入到一个大文件中，接着采用映射的方法，比如 %1000，把整个大文件映射为 1000 个小文件。

2. hash_map 统计

当大文件转换成小文件，便可以采用 hash_map 分别对 1000个小文件中的 IP 进行频率统计，再找出每个小文件中出现频率最大的那个 IP。

3. 堆 / 快速排序

统计处 1000 个频率最大的 IP 后，依据各自频率的大小进行排序，按时间复杂度或者空间复杂度考虑排序算法。

### 业务—订单场景

#### 1. 一笔订单，在取消的那一刻，用户刚好付款了，怎么办？

订单会有定时取消的逻辑，所以会出现用户卡点付款的场景，所以会出现两种情况：

1. 用户支付成功，支付回调的那一刻支付单刚好还没取消，而等回调结束，取消支付单的事务提交，支付单取消。此时用户扣款了，但是对应的资产没了。
2. 用户支付成功，支付回调的那一刻支付单已经被取消。但此时用户已经扣款，东西没了。

这种场景是支付单支付成功和取消的两种状态竞争，正常情况下，订单或者支付单都会有状态机的存在，在当前场景简单来说有以下两条路径：

1. 待支付->支付中->支付成功
2. 待支付->支付中->已取消

针对上述的情况 1 就是路径 1，针对情况 2 就是路径 2

所以在修改支付单状态的时候，基于原始状态的判断，就可以正常的处理

```sql
# 支付成功
update pay_info set status = 'paySuccess' where orderNo = '1' and status = 'paying';

# 取消
update pay_info set status = 'cancel' where orderNo = '1' and status = 'paying';
```

当加了`status = 'paying'`就可以保证一个成功一个失败。当情况 1 执行成功，那么取消的 sql 必定执行失败，不需要做额外的处理。当情况 2 执行成功，订单被取消，支付成功的 sql 必然失败，这时候就要逆向处理，给用户退款。

这里在业务上有一个优化，用户可能会纠结在最后一刻决定付款，如果这时候被告知退款，可能不会再下单了，因此可以在页面上限时订单倒计时为 10 分钟，实际的后端是延迟 11 分钟取消。

除了利用数据库的处理，还可以使用分布式锁，对一笔订单加锁也能保证这笔订单正常的业务流转。

#### 2. 项目上发现出现很多重复订单，怎么处理？

出现重复订单的情况是因为系统针对下单的方法没有做幂等的设计。

大致可以通过两种方式来实现下单的幂等：

1. 数据库唯一约束

可以将订单号作为数据库的主键或者唯一索引，这样一来，数据库就会拒绝重复插入的情况，避免重复订单。

2. 分布式锁

可以用分布式锁来避免多个请求同时处理同一笔订单的情况，这里需要注意的是，lock 的 key 要以`order_lock_{orderID}`这种订单号的维度加锁，避免同笔订单多次插入的同时锁的粒度也足够细。

如果只以`order_lock`作为 key，那么下单的方法并发度就是 1，性能会下降。

## 系统设计