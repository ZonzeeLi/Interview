# 面试题5

## 业务相关

### JWT 是怎么工作的

JWT 主要是由 Header、Payload、Signature 三部分组成：

Header：包含算法和 token 类型；
Payload：有效负载，包含实体数据信息；
Signature：签名，用来验证。

用户首次认证之后，会通过用户的部分唯一个人数据，比如用户名密码，生成一个 JWT 返回，之后的请求用户可以直接带着这个 Token 请求来验证，JWT 的验证是由服务端通过算法和私钥将 payload 解析与 signature 比对，不需要访问数据库，验证成功会返回服务端资源。

### JWT 有什么缺点

1. 服务器不保存会话状态，即一旦签发，有效期内会一直有效；
2. 安全性问题，jwt 的用户数据没有加密，需要考虑脱敏问题；
3. 不支持续签，一旦过期就需要重新生成。

### 如何解决 JWT 长时间有效的问题

可以使用 redis  来维护 JWT 的白名单和黑名单，在每次颁发 JWT 时，将用户的 id 作为 key 保存在 redis ，如果有操作需要主动终止 JWT 的有效，则删除 Redis 中的 key 移除白名单或者移入黑名单，如果再次验证发现用户的 key 不存在 redis，则认证失败。

## Go 相关

### Go 和 Python 有什么区别？Go 有什么优势？

Go 语言的的编译速度快、高并发性能好，部署更简单。

- Go 允许跨平台编译，编译出来的是二进制的可执行文件，直接部署在对应系统上即可运行。
- Go 在语言层次上天生支持高并发，通过 goroutine 和 channel 实现。channel 的理论依据是 CSP 并发模型， 即所谓的通过通信来共享内存；Go 在 runtime 运行时里实现了属于自己的调度机制：GMP，降低了内核态和用户态的切换成本。

### Go 的协程和 Python 的线程有什么区别？

- 线程是任务调度和系统执行的最小单位，协程是用户态的轻量级线程；
- 线程有自己的内存空间也有共享空间，协程有自己的寄存器保存上下文，线程携带的资源大于协程；
- 线程的切换开销发生在内核态，协程发生在用户态，开销大于协程。

（这里直接回答协程和线程的区别）

### 为什么协程资源占用会低一些

goroutine不涉及到内核态的东西，它的空间也是有runtime管理的，协程自己有寄存器存储上下文，跟线程在内核态频繁的切换占用资源不一样，也没有线程需要的那么多资源，所以初始化比较小（2kb），但可以动态分配。

### 开海量的协程和开海量的线程有什么区别

主要区别就是开海量的线程可能实际正在运行的线程很少，受到 CPU 核数的影响，而且线程默认的开辟空间是 8MB，相比海量的协程（2KB）更占用资源，协程理论上可以创建成千上万个，比如 go 语言可以在一个线程上让多个协程调度执行，这是由 GMP 实现的，同时协程的作用空间在用户态，线程在内核态，切换资源开销，海量协程都要好很多。

### 为什么线程比较消耗资源，如果用线程池呢？

1. 占用空间，默认是 8MB，有自己的内存空间和共享空间；
2. 切换开销大，切换发生在内核态，且线程间切换涉及到锁；
3. 无法控制，线程只是任务的调度和执行，多线程的执行顺序是随机的，要通过进程来管理（这个我不确定，之前看到过线程的调度交给进程去做）。

线程池可以用来管理线程，可以降低资源的消耗、提高响应速度，主要是复用已经创建的线程，来减少创建、效果线程的消耗，

### 协程和线程并发能力水谁强，为什么？

协程，原因在上面，这几个问题其实总结下来就是一类问题，就是进程、线程、协程的区别。

### 不管是协程还是线程，最终都是交给系统调度的，最终都是落到线程上执行，那就是说真正的并发能力是取决于系统的硬件对不对？为什么要说协程的并发能力要比线程强？

同样是上述的内容，然后讲述 GMP。因为这些所以协程的并发能力要比线程强

调度过程是一个 M 绑定一个 P，P 中有本地队列，包含 goroutine，go 语言的调度器会将 G 调度到 M 上运行，如果有新创建的 G 会放到 P 的本地队列中，当一个正在被 M 执行的 G 执行结束后，会发生切换，如果有多个 G 创建超过了 P 的本地队列的长度，会将本地队列中的前一半和当前创建的 G 放入到全局队列中。当创建新的 G，运行的 G 会尝试去唤醒空闲的 M 绑定 P，如果唤醒的 M 的 P 的本地队列中没有 G，会进入自旋状态，尝试从全局队列中获取 G，如果全局队列中。另外可能发生运行的 G 阻塞导致 M 阻塞，这时候 P 会去寻找空闲的其他 M 继续执行，等原先阻塞的 M 恢复了，会优先寻找原先的 P，没有找到该 M 会进入空闲队列，G 会进入全局队列。

### 如果说我现在有 4 个计算任务，我的 CPU 是 4 核的，我开了 4 个线程和开了 4 个协程做对比，哪个性能高一点

以 go 语言为例，如果是 4 个 G 分别在每个 M 的 P 中，那么其实和 4 个 M 执行很相似，本质还是线程和协程的区别，如果是 4 个 G 在一个 M 中，那么其实并没有利用到多核的优势，这里其实创建更多个协程可以充分发挥 CPU 利用率。所以这里其实可以根据任务的类型来做区分，如果是 CPU 密集型，4 个线程可以充分发挥多核的优势，如果是 IO密集型和计算密集型，在高并发和低延迟的角度，4 个协程会更好。

### 我启动了一个协程，又启动了很多个子协程，现在父协程需要让子协程立即停止，该如何去设计

1. 可以使用父子 context 去设计，子 context 由父 context 生成，父 context 执行 cancel，会连同自己和所有的子协程停止；
2. 使用 channel，子协程执行阻塞，收到来自父协程的停止信号退出。

### context.Done 是如何实现的

context.Done 是返回一个只读的 channel，如果 context 被取消或者 timeout，这个 channel 会被关闭，比如父协程主动执行 cancel 会发送一个停止信号，子协程会收到消息，执行结束。

### context.Done 是如何做到使用一个 chan 让所有子协程收到消息的

父协程创建一个子 context，传递给所有的子 goroutine，然后所有的子 goroutine 通过 for select 监听 <-ctx.Done()，收到停止信号就手动 return，父协程 cancel 后，会发送停止信号，close chan，然后所有子协程会从关闭的通道收到零值。

### go 如何做整数的原子自增

通过atomic包的addint函数

### map 的实现

map 的底层数据结构是 hmap，主要的字段有一个字段 B，由 2^B 表示桶数，其中有一个 buckets 指针指向 bmap 的数组，另外一个 oldbuckets 也是指向 bmap 的数组，用来在扩容到的时候使用，还有一个 extra 指向溢出桶的指针，其中每一个 bmap 主要是由 tophash、key、value、溢出桶指针组成，一个 bmap 可以存放 8 对 kv，tophash 是用来快速判断对应槽位的 key 是否存在。

### map 如何解决哈希冲突

首先要明确什么是哈希冲突，key 根据哈希函数计算出哈希值，然后取模得到索引位置，但是可能会出现两个不同的 key，计算得到的哈希值相同，这样就会出现哈希冲突的问题。

map 解决哈希冲突的方法是链地址法。普通的链地址法是 map 中的桶以数组和链表的形式来记录kv，比如两个 key 哈希冲突了，那么会一个 key 接到 一个 key 的后面。go 中的链地址法是如果冲突了先在bucket里面往下顺位找空位，如果满了会在溢出桶中找，也满了会在创建一个溢出桶插入在第一个空位上。

### 并发访问 map 有什么问题

map不是线程安全的，会产生资源竞争，并发读写会产生fatal error。

## 其他

### docker 的工作原理

（应该不是问docker的底层原理，底层原理是一套复杂的路由机制和隔离机制，我觉得不会问）

docker 的主要组成分为：

- docker 引擎：负责管理和运行容器；
- 镜像：运行应用程序的文件系统和环境；
- 容器：将镜像实例化，具有自己的文件系统、网络、进程，每个容器之间是互相隔离的；
- 仓库：镜像的存储地址。

整个原理就是基于容器化技术，将应用程序打包成镜像，构建容器运行，从而快速部署、跨平台、资源隔离。

### 文件上传在 http 中是如何工作的

http 中文件上传使用的是表单（form）的方式，通过 post 方式，将请求数据和文件数据以多表单发送给服务端，服务端会通过分隔符获取内容，从每部分解析后保存到临时文件。

### 系统中有一个大文件，我需要快速且频繁的读写它，要怎么优化（文件巨大）

首先要知道问题会发生什么，会导致可用内存减少，这个大文件一直占用内存空间。

1. 大文件拆分成小文件；
2. 并发批读取，如果逐行读取会非常慢，可以并发解决。
3. 流式传输，避免一次读入整个文件。

## MySQL 相关

### MySQL 的索引分类

- 按照索引类型分类：B树索引、哈希索引、fulltext 索引；
- 按照存储方式的索引：聚簇索引、非聚簇索引；
- 按照使用的列的个数：单列索引、联合索引；
- 按照使用的字段：主键索引、唯一索引、前缀索引、普通索引

### 如果查询没有索引，那么它的查询流程是什么？

如果查询没有索引，走的是全表扫描，全表扫描的过程是线性扫描，将所有表中的记录逐行扫描，首先数据库会将数据页读到磁盘缓冲区，然后逐行扫描比对，如果该页没有就回去磁盘上再读一页。

还有记住完整的一条语句查询流程：

1. 首先通过连接器，建立与 MySQL 的连接；
2. 然后通过查询缓存查找数据，如果命中直接返回（在 MySQL 8.0 中被删除了，如果有更新操作，那么）；
3. 然后通过解析器对 SQL 语句进行词法分析和语法分析，构建语法树，如果语法不对则报错；
4. 然后 MySQL 的优化器会基于查询成本，选择查询成本最小的执行计划；
5. 最后通过执行器来执行，去存储引擎中查询到记录返回。

### 如果没有命中索引有需要排序呢？

（这问题很奇怪，没什么意义，有点没理解他想问的是，要怎么优化？还是这时候的流程是如何的？）

优化就是索引优化。

如果是流程，会执行全表扫描的流程，然后会将所有的记录保存在缓冲区buffer（记不清是这里还是临时表了），然后会对数据进行排序，应该是快速排序或者递归排序。

### 如果有 1 亿条数据，我只需要取其中 10 条该怎么办

1. 分库分表。将表的数据分表之后，确定好具体的页和位置，减少遍历回表次数。
2. 使用 limit。一次读取10条，避免多余的回表。
3. 对查询字段建立索引。使用索引 where 条件时可以快速查找。
4. 可以考虑主从读写分离。主库用来写，从库用来读。

### 如果我查询的数据非常大，比如说 1 亿条数据，又需要排序，会 OOM 吗？

会，如果数据量过大，在内存中进行排序，内存不够，会导致 OOM。

这时候可以考虑分批处理，比如加 limit 限制、分页等设计。

### MongoDB 和 MySQL 有什么区别？

- MySQL 是关系型数据库，MongoDB 是非关系型数据库；
- MySQL 默认是 InnoDB 引擎，MongoDB 是类 JSON 的文档存储；
- 大数据处理上 MongoDB （因为 MongoDB 自带分片机制，且将热数据存在内存上）有优势，而 MySQL 的结构性更好；
- MySQL 支持事务，MongoDB不支持（最新版好像也支持了）。

### MySQL 后期增加列时会有什么问题

如果是大表在线上增加列，会锁表，导致其他语句不能执行，容易造成业务崩溃。

可以回答一下对 DDL 的解决方案，比如 pt-online-schema-change，创建一张与原表相同的表，对新表进行 DDL，在原表上创建3个触发器（DELETE\UPDATE\INSERT），用来原表复制到新表时的数据改动时的同步，将原表数据以数据块（chunk）的形式复制到新表，然后交换，原表重命名为old表，新表重命名原表名，最后删除旧表，删除触发器。


