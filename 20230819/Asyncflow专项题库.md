# Asyncflow 专项题库

## 项目立意

### 介绍下你的项目

这个项目其实是一个框架，主要负责的是异步任务的创建、拉取、执行等功能。主要分成两部分，服务端封装好了任务创建、设置、拉取的接口逻辑，客户端只需要直接调用即可，而且其中还涉及到了分表设计、任务优先级设计、重试机制等，客户端写好了异步执行调用接口，并循环拉取任务执行处理逻辑，只需要对参数封装成上下文，修改执行逻辑为自己的逻辑即可。

### 你为什么做这个框架，什么场景使用这个框架

做框架的目的主要是将这种异步执行调用和任务的创建等存在大量重复性的代码抽象成接口逻辑，只需要稍加修改、配合实际场景就可以使用，加快开发的效率。

比如在一些音视频场景中经常会有传输音视频流的使用，但是在传输的时候，用户只需要看到一个实时的进度即可，其他时间可以操作其它功能，这时候就涉及到异步使用。

### asyncflow和消息队列有什么区别

asyncflow 是一个服务框架，能做的事情更多，能将功能封装成接口，任务的拉取、执行、更新也统一化，开发者只需要更改参数和自己的处理逻辑即可。消息队列更多的是处理事件的分发、消息的流转，只是一个中间件，做不到框架能提供的更多任务上自定义的操作。

### 为什么不用业界已有的异步任务框架

目的是自主开发的一个轻量级异步框架。

### 这个项目是你一个人做的还是团队做的？你们是怎么协作的

整体框架的架构设计和流程设计是由我设计的，比如任务拉取、执行、调度的完整规则，以及数据库的表设计也是由我做的，比如优先级字段、分表的设计。而其他的接口功能是由团队成员设计的，比如执行任务、获取任务的具体接口。

### 你的使用场景是什么

我的使用场景之一是一个音视频合成分发的场景，因为我们负责的是语音模块，有tts语音合成部分，当用户想要合成音频文件的话，可以从前端获取到用户想要的参数，比如音色、发音人、音量、音调、合成文本信息等等，这些参数作为worker的上下文，在具体的执行逻辑部分调用我们内部的合成接口，异步执行，让合成部分在后台处理，而这一步对用户是不透明的，可以进行其他的操作。

## 你的使用场景是什么

### 你的框架怎么接入呢

客户端调用拉取任务的worker可以根据自己的参数需求来定义结构体保存在上下文中，并根据自己的需求更改处理逻辑即可，另外可以对任务拉取执行的重试次数、重试间隔进行更新，其他的功能只需要调用接口就行。服务端提供封装好的接口，可以根据自己的需求增加表结构字段，可以根据实际的需求来增加接口。

### 你的框架怎么部署呢

我们的整体服务是走 cicd 部署到公司服务器上，运行在docker容器中，目前正在准备迁移到k8s上管理，我们正在配置。flowsvr和worker都在docker中启动3个，宕机了自动重启，并会有报警，flowsvr的mysql和redis也是采用3个部署主从模式。

### worker是托管在框架这边的服务器吗？还是在对于异步任务的模块？如果worker托管在异步任务处理框架这边的服务器，那处理完之后的数据怎么回写到业务方的数据库？（美团一面）

worker 不需要托管在框架的服务器，客户端和服务端只要能网络访问通即可，flowsvr 和 worker 是可以分开部署的。

如果是托管到了异步任务处理框架这边的服务器，处理完的任务数据，可以以日志的形式发送奥消息队列，由业务方的 es 采集。

## 存储

### 为什么存储用MySQL不用Redis？

因为首先我们的数据量可能会庞大，考虑到 Redis 是内存型数据库，避免占用过多的内存。其次 MySQL 的查询要比 Redis 方便很多，提供多种查询方式，而 Redis 是用 key，Redis 更多是用在一些需要缓存的场景，如果这里客户端有很多查询的场景，那么可以接入 Redis 来作为缓存。

### 为什么存储用MySQL不用MongoDB？

MongoDB的使用场景多数是文档型的内容，比如聊天记录信息等，用 MySQL 来存储是比较简洁，且字段结构型比较好。

### 上下文怎么存储的，存不下怎么办？

上下文是通过结构体参数来存储的，相当于将处理逻辑需要的参数进行保存。一般来说都是足够存储的，如果存不下的话，可以额外再使用一个表或者redis，根据userid客户端调用方信息来保存需要使用的上下文信息。

## 任务调度

### 讲讲任务创建的流程 

客户端可以调用flowsvr的任务创建接口，经过参数检查之后，插入具体的tasktype任务类型的一条记录，由于我们做了分表设计，所以要插入在新表中。

### 讲讲拉取任务接口的流程

任务拉取是客户端根据具体的tasktype任务类型来拉取，在拉取前首先要加分布式锁，防止多个worker同时抢任务的并发问题，会通过tasktype任务类型字段去 MySQL 中，按照优先级其状态是等待执行pending状态的任务拉取一定的任务返回，然后解锁。等任务处理完之后，会在进行一轮新的拉取。

### 任务拉取按什么顺序

任务拉取按照优先级的顺序来拉取。

### 优先级是怎么做的

优先级是经过考虑后使用order_time的字段来设定的。首先如果使用create_time来作为优先级的判断，那么很可能会导致一种情况，某一个早期任务一直失败，每次循环拉取任务都能拉取到这个任务，导致占用过的资源，如果该种任务过多会导致卡死。其次如果使用 modify_time 来作为优先级的判断，我们项目的最开始的设计有重试间隔，如果用修改时间来排序会导致重试间隔失效，还没达到重试间隔就会被worker拉取。然后如果定义一个priority字段来表示优先级，由于大部分任务的优先级可能一样，尽管建立索引，也会走全表扫描降低性能。

所以使用了一个order_time字段来替代priority，order_time 的定义是，利用创建时间 - 优先级，比如我们优先级是10，相当于这个任务提前了10s创建，如果是我们有重试间隔，在执行一次任务失败或者没完成后，只需要将 order_time 加上重试间隔即可。

### 重试间隔是什么机制

重试间隔是保证执行某个任务，如果任务失败了或者还没处理完，我们可以过段时间重试，避免循环拉取这个任务让服务卡死。重试间隔采用渐进式的成长，比如我们设置最大的重试间隔是10s，那么1个任务的重试间隔就从1、2、4、8、10这样成长。

### 任务如果执行中失败了怎么办

任务如果执行失败了，会进行重试，这样可以被再次拉取到再执行，如果是超过了最大重试次数，那么就将状态改为失败状态。

### Worker怎么竞争任务

worker的竞争是用分布式锁实现的，key设定为任务类型，比如两个处理a任务的worker需要抢锁，抢到锁的占据任务，之后释放锁。

### 为什么不用MySQL自带的锁？

用 MySQL 的 for update 确实可以实现类似的功能，但是会产生间隙锁会对其他记录有影响，同时 MySQL 如果有大量的请求也要考虑 MySQL 性能的问题。

### 用了分布式锁，一个任务就一定不会被多个worker同时拿到吗？

不一定。比如一个worker拿到锁了之后陷入了gc，这时候锁过期了，另一个worker就拿到了锁，所以就会出现同时拿到锁的情况。

### 竞争分布式锁这种方式，会不会有什么问题

多个 worker 竞争分布式锁可能会导致，一个 worker 抢到，其他 worker 都在阻塞等待它的释放，导致资源浪费。

### 不使用Redis，如何解决多机竞争问题？设计一个新方案

可以使用消息队列将任务拉取和任务执行解耦，将拉取的任务都丢进到消息队列里，分发到worker中，worker自己执行自己的任务。

### 你采用的是多台worker竞争任务的方式，那这样会不会出现有些worker在执行大量任务但是一部分worker处于空闲的状态呢？(滴滴一面）

可能会出现，由于 worker 的竞争锁问题，但是 worker 在获取到任务之后，就会释放锁，其他 worker 可以再去获取锁了，整个锁释放的过程是很快的，很难出现一部分 worker 出浴空闲状态。

### 任务如果执行中如果worker挂掉怎么办

我们的框架还有一部分任务监控的部分，worker 如果在执行中挂掉了，任务监控模块可以在数据库中查询到超时执行的任务，并将任务的状态重置，等待下一次被其他 worker 拉取到，另外如果是部署在 k8s 上会自动重启崩掉的 worker，保证整体的稳定性。

### 如果突然有特别多数据怎么处理呢？不考虑对worker进行扩容，不考虑增加机器，比如就多了50%这样的需求，框架的的瓶颈在什么地方？这个模块会出什么问题（腾讯二面思考题）

框架的一部分瓶颈在于锁机制一直是影响性能的问题之一，所以如果不使用分布式锁的话，可以使用消息队列来做，利用消息队列，中间有一个服务将任务拉取到消息队列中，然后分给各个 worker 执行，保证最大利用率。另外如果请求实在过多，可以利用消息队列的削峰处理，将过多的数据存在队列中，等之后再执行。

## 分表

### 分表为什么自己写 ，为什么不用组件 ？

这里涉及的分表是根据一张表的数据量超过一定阈值之后，就扩展出一张新表，和普通的水平分表有点不同，业内的组件虽然功能庞大，但是引入新组件也有开发和维护成本，本身这个框架的表设计就没有水平分表的场景，所以为了降低成本，自己实现即可。

### 介绍你的分表方式？

利用两个字段，一个是数据开始在哪一张表，一个是数据结束在哪一张表，最开始两个字段都是1，表示只有一张表，当一张表的记录过多，并且所有任务还没有被 worker 处理完，这时候就需要将数据结束在哪一张表的值+1，也就是创建了一张新表，新的任务创建都创建在这张表上，等之后任务拉取旧表，拉取不到待执行的任务，就说明旧表中的任务都被执行完了，这张表就没用了，可以设定过期时间将表删除。

### 为什么按大小分表？

按大小分表可以将处理过的任务和还没处理的任务分割开，比如旧表中的大部分任务是都被处理的，新表中大部分都是新创建的任务，因为我们的拉取任务的逻辑就是，从旧表中获取先拿。

### 你为了机器人项目做了一个框架？你量这么小，弄500w分表？

这里的考虑是可能没有那么高的请求量，但是我们要考虑到扩展，不能没有这样的设计。框架是要考虑到场景的，不单单为了一个业务需求服务。

### 如果读写请求大到单表处理不过来呢？

正常来说在一般的异步任务场景下是不会发生这样的情况，但就很是出现这样的情况，可以根据 userid 客户端的信息再次分片，hash 分片的方式，根据 userid 来判断到哪一个 MySQL 节点操作。

### 会不会出现schedule_beign_pos和schedule_end_pos跨不止1张表的情况？

可能会，如果旧表中的任务处理过慢，且同时又有大量的任务创建，就可能会出现这样的情况。

### 推荐分表的阈值是多少？为什么这么推荐？

默认是 500w。之前看过阿里巴巴团队的文章，虽然 MySQL 的 B+ 树结构，在 2000w 数据量的时候还能维持稳定的层数，但是他们推荐在 500w 数据量的时候就要考虑分库分表了，阿里巴巴毕竟有很多海量数据场景的经验，所以参考的大厂的设置。

## 性能

### 你这个框架的性能怎么样

在我们的月数据量接近百万数量级别的实际生产环境中，目前维持的比较稳定。

### 你是怎么测试的 

我是模拟并发请求进行压测的，可以使用postman或者自己写程序开goroutine模拟请求，测出响应时间、吞吐量、错误率、CPU使用，服务端运行在16核64G的服务器上，在网络、客户端硬件配置正常的情况下，可以维持稳定性。

